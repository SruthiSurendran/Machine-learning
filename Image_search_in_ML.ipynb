{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image search in ML",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMC47OSMSvB9y3TCGcm54ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SruthiSurendran/Machine-learning/blob/main/Image_search_in_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJausiXowyT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRm711TToyH9"
      },
      "source": [
        "## **Step 1: Defining our Image Descriptor** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uilyUL--dl4f"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0oTukKFkMgg"
      },
      "source": [
        "class ColorDescriptor:\n",
        "\tdef __init__(self, bins):\n",
        "\t\t# store the number of bins for the 3D histogram\n",
        "\t\tself.bins = bins\n",
        "\tdef describe(self, image):\n",
        "\t\t# convert the image to the HSV color space and initialize\n",
        "\t\t# the features used to quantify the image\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\t\tfeatures = []\n",
        "\t\t# grab the dimensions and compute the center of the image\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\t(cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw1_nX6sl10d"
      },
      "source": [
        "The __init__ method of the ColorDescriptor takes only a single argument, bins , which is the number of bins for our color histogram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23YsKFMLmTGL"
      },
      "source": [
        "We can then define our describe method on Line 11. This method requires an image , which is the image we want to describe.Inside of our describe method we’ll convert from the RGB color space (or rather, the BGR color space; OpenCV represents RGB images as NumPy arrays, but in reverse order) to the HSV color space, followed by initializing our list of features to quantify and represent our image ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPkF0wWVlx_P"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Ut9Kl7m6xB"
      },
      "source": [
        "# divide the image into four rectangles/segments (top-left,\n",
        "\t\t# top-right, bottom-right, bottom-left)\n",
        "\t\tsegments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h),\n",
        "\t\t\t(0, cX, cY, h)]\n",
        "\t\t# construct an elliptical mask representing the center of the\n",
        "\t\t# image\n",
        "\t\t(axesX, axesY) = (int(w * 0.75) // 2, int(h * 0.75) // 2)\n",
        "\t\tellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
        "\t\tcv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
        "\t\t# loop over the segments\n",
        "\t\tfor (startX, endX, startY, endY) in segments:\n",
        "\t\t\t# construct a mask for each corner of the image, subtracting\n",
        "\t\t\t# the elliptical center from it\n",
        "\t\t\tcornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
        "\t\t\tcv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
        "\t\t\tcornerMask = cv2.subtract(cornerMask, ellipMask)\n",
        "\t\t\t# extract a color histogram from the image, then update the\n",
        "\t\t\t# feature vector\n",
        "\t\t\thist = self.histogram(image, cornerMask)\n",
        "\t\t\tfeatures.extend(hist)\n",
        "\t\t# extract a color histogram from the elliptical region and\n",
        "\t\t# update the feature vector\n",
        "\t\thist = self.histogram(image, ellipMask)\n",
        "\t\tfeatures.extend(hist)\n",
        "\t\t# return the feature vector\n",
        "\t\treturn features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKkUXwZOn2B0"
      },
      "source": [
        "def histogram(self, image, mask):\n",
        "\t\t# extract a 3D color histogram from the masked region of the\n",
        "\t\t# image, using the supplied number of bins per channel\n",
        "\t\thist = cv2.calcHist([image], [0, 1, 2], mask, self.bins,\n",
        "\t\t\t[0, 180, 0, 256, 0, 256])\n",
        "\t\t# normalize the histogram if we are using OpenCV 2.4\n",
        "\t\tif imutils.is_cv2():\n",
        "\t\t\thist = cv2.normalize(hist).flatten()\n",
        "\t\t# otherwise handle for OpenCV 3+\n",
        "\t\telse:\n",
        "\t\t\thist = cv2.normalize(hist, hist).flatten()\n",
        "\t\t# return the histogram\n",
        "\t\treturn hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV7CqSbEoFLC"
      },
      "source": [
        "histogram method requires two arguments: the first is the image that we want to describe and the second is the mask that represents the region of the image we want to describe.Calculating the histogram of the masked region of the image is handledmaking a call to cv2.calcHist using the supplied number of bins from our constructor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1hNAyN-odp8"
      },
      "source": [
        "Our color histogram is normalized to obtain scale invariance. This means that if we computed a color histogram for two identical images, except that one was 50% larger than the other, our color histograms would be (nearly) identical. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf-mo51bpDlU"
      },
      "source": [
        "## **Step 2: Extracting Features from Our Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9cvEzYoPGT"
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.colordescriptor import ColorDescriptor\n",
        "import argparse\n",
        "import glob\n",
        "import cv2\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-d\", \"--dataset\", required = True,\n",
        "\thelp = \"Path to the directory that contains the images to be indexed\")\n",
        "ap.add_argument(\"-i\", \"--index\", required = True,\n",
        "\thelp = \"Path to where the computed index will be stored\")\n",
        "args = vars(ap.parse_args())\n",
        "# initialize the color descriptor\n",
        "cd = ColorDescriptor((8, 12, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBdtMVQmpxyt"
      },
      "source": [
        "argparse for parsing command line arguments, glob from grabbing the file paths to our images, and cv2 for OpenCV bindings.Parsing our command line arguments is handled on Lines 8-13. We’ll need two switches, --dataset , which is the path to our vacation photos directory, and --index which is the output CSV file containing the image filename and the features associated with each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7icNzMjtp5Vn"
      },
      "source": [
        "# open the output index file for writing\n",
        "output = open(args[\"index\"], \"w\")\n",
        "# use glob to grab the image paths and loop over them\n",
        "for imagePath in glob.glob(args[\"dataset\"] + \"/*.png\"):\n",
        "\t# extract the image ID (i.e. the unique filename) from the image\n",
        "\t# path and load the image itself\n",
        "\timageID = imagePath[imagePath.rfind(\"/\") + 1:]\n",
        "\timage = cv2.imread(imagePath)\n",
        "\t# describe the image\n",
        "\tfeatures = cd.describe(image)\n",
        "\t# write the features to file\n",
        "\tfeatures = [str(f) for f in features]\n",
        "\toutput.write(\"%s,%s\\n\" % (imageID, \",\".join(features)))\n",
        "# close the index file\n",
        "output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWC0ghJPqH8c"
      },
      "source": [
        "$ python index.py --dataset dataset --index index.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edB660kRqVw2"
      },
      "source": [
        "Running a wc on the index, we can see that we have successfully indexed our dataset of 805 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kQ2eJ4qI-t"
      },
      "source": [
        "$ wc -l index.csv\n",
        "     805 index.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6jbFXYqeHc"
      },
      "source": [
        "# Step 3: The Searcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iyJGmlCqjlA"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import csv\n",
        "class Searcher:\n",
        "\tdef __init__(self, indexPath):\n",
        "\t\t# store our index path\n",
        "\t\tself.indexPath = indexPath\n",
        "\tdef search(self, queryFeatures, limit = 10):\n",
        "\t\t# initialize our dictionary of results\n",
        "\t\tresults = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6BpfF2Tq17R"
      },
      "source": [
        "We’ll go ahead and import NumPy for numerical processing and csv for convenience to make parsing our index.csv file easier.The constructor for our Searcher will only require a single argument, indexPath which is the path to where our index.csv file resides on disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO9YBPvZrD5w"
      },
      "source": [
        "# open the index file for reading\n",
        "\t\twith open(self.indexPath) as f:\n",
        "\t\t\t# initialize the CSV reader\n",
        "\t\t\treader = csv.reader(f)\n",
        "\t\t\t# loop over the rows in the index\n",
        "\t\t\tfor row in reader:\n",
        "\t\t\t\t# parse out the image ID and features, then compute the\n",
        "\t\t\t\t# chi-squared distance between the features in our index\n",
        "\t\t\t\t# and our query features\n",
        "\t\t\t\tfeatures = [float(x) for x in row[1:]]\n",
        "\t\t\t\td = self.chi2_distance(features, queryFeatures)\n",
        "\t\t\t\t# now that we have the distance between the two feature\n",
        "\t\t\t\t# vectors, we can udpate the results dictionary -- the\n",
        "\t\t\t\t# key is the current image ID in the index and the\n",
        "\t\t\t\t# value is the distance we just computed, representing\n",
        "\t\t\t\t# how 'similar' the image in the index is to our query\n",
        "\t\t\t\tresults[row[0]] = d\n",
        "\t\t\t# close the reader\n",
        "\t\t\tf.close()\n",
        "\t\t# sort our results, so that the smaller distances (i.e. the\n",
        "\t\t# more relevant images are at the front of the list)\n",
        "\t\tresults = sorted([(v, k) for (k, v) in results.items()])\n",
        "\t\t# return our (limited) results\n",
        "\t\treturn results[:limit]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9-iu0UprP-W"
      },
      "source": [
        "For each row, we extract the color histograms associated with the indexed image and then compare it to the query image features using the chi2_distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1OYfW2grUmK"
      },
      "source": [
        "def chi2_distance(self, histA, histB, eps = 1e-10):\n",
        "\t\t# compute the chi-squared distance\n",
        "\t\td = 0.5 * np.sum([((a - b) ** 2) / (a + b + eps)\n",
        "\t\t\tfor (a, b) in zip(histA, histB)])\n",
        "\t\t# return the chi-squared distance\n",
        "\t\treturn d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JReGQEA8rav6"
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.colordescriptor import ColorDescriptor\n",
        "from pyimagesearch.searcher import Searcher\n",
        "import argparse\n",
        "import cv2\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--index\", required = True,\n",
        "\thelp = \"Path to where the computed index will be stored\")\n",
        "ap.add_argument(\"-q\", \"--query\", required = True,\n",
        "\thelp = \"Path to the query image\")\n",
        "ap.add_argument(\"-r\", \"--result-path\", required = True,\n",
        "\thelp = \"Path to the result path\")\n",
        "args = vars(ap.parse_args())\n",
        "# initialize the image descriptor\n",
        "cd = ColorDescriptor((8, 12, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8GczddUrttV"
      },
      "source": [
        "# load the query image and describe it\n",
        "query = cv2.imread(args[\"query\"])\n",
        "features = cd.describe(query)\n",
        "# perform the search\n",
        "searcher = Searcher(args[\"index\"])\n",
        "results = searcher.search(features)\n",
        "# display the query\n",
        "cv2.imshow(\"Query\", query)\n",
        "# loop over the results\n",
        "for (score, resultID) in results:\n",
        "\t# load the result image and display it\n",
        "\tresult = cv2.imread(args[\"result_path\"] + \"/\" + resultID)\n",
        "\tcv2.imshow(\"Result\", result)\n",
        "\tcv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8YmKNDNs_vr"
      },
      "source": [
        "## query images\n",
        "$ python search.py --index index.csv --query queries/108100.png --result-path dataset\n",
        "$ python search.py --index index.csv --query queries/103300.png --result-path dataset\n",
        "$ python search.py --index index.csv --query queries/115100.png --result-path dataset\n",
        "$ python search.py --index index.csv --query queries/115100.png --result-path dataset\n",
        "$ python search.py --index index.csv --query queries/103100.png --result-path dataset\n",
        "$ python search.py --index index.csv --query queries/127502.png --result-path dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkoONeRrwBS_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mik0sTW_wqdj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}